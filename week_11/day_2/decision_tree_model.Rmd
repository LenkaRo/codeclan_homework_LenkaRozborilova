---
title: "R Notebook"
output: html_notebook
---

Decision trees homework

In this homework we will create a decision tree to see which factors are useful in predicting whether or not a passenger on the titanic will survive.

Run the code below before you begin:

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)
library(GGally)
library(janitor)
library(modelr)
library(yardstick)
library(caret)

titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

Data Dictionary

sex: Biological Sex, male or female
age_status: adult or child (child defined as under 16)
class : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)
port_embarkation: C = Cherbourg, Q = Queenstown, S = Southampton
sibsp : number of siblings / spouses aboard the Titanic
parch: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them.
survived_flag : did they survive, 0 = No, 1 = Yes


# MVP

## 1.1 Question 1

Cleaning up the data is always the first step. Do the following:

Take only observations which have a survived flag (i.e. that aren’t missing)
Turn your important variables into factors (sex, survived, pclass, embarkation)
Create an age_status variable which groups individuals under (and including) 16 years of age into a category called “child” category and those over 16 into a category called “adult”.
Drop the NA
Drop any variables you don’t need (X1, passenger_id, name, ticket, far, cabin)
If you need help doing this, the code is below, but please try it yourself first so you can learn!

```{r}
# tidy data
titanic_set <- titanic_set %>% 
  filter(!is.na(survived)) %>% 
  mutate(
    sex = as.factor(sex),
    survived = factor(survived, levels = c(0, 1), labels = c("No", "Yes")),
    pclass = as.factor(pclass),
    embarked = as.factor(embarked)
  ) %>% 
  mutate(
    age_status = if_else(age <= 16, "child", "adult") %>% as.factor()
  ) %>% 
  select(-c("X1", "passenger_id", "name", "ticket", "fare", "cabin", "age")) %>% 
  drop_na()
  
glimpse(titanic_set)
```

## 1.2 Question 2

Have a look at your data and create some plots to ensure you know what you’re working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.

```{r}
titanic_set %>% 
  ggpairs(progress = FALSE)
```

Looks like `age_status`, `sex` and `pclass` might be potentially significant predictors

Let's have a closer look at some variables

```{r}
# looks like in proportion, children had higher chance to survive than adults
titanic_set %>% 
  ggplot() +
  aes(x = survived, fill = age_status) +
  geom_bar()

# looks like in proportion, females had higher chance to survive than males
titanic_set %>% 
  ggplot() +
  aes(x = survived, fill = sex) +
  geom_bar()

# slightly higher death rate among passenger traveling in 3rd class
titanic_set %>% 
  ggplot() +
  aes(x = survived, fill = pclass) +
  geom_bar()
```

## 1.3 Question 3

Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [Extra - if you want to force balanced testing and training sets, have a look at the stratified() function in package splitstackshape (you can specify multiple variables to stratify on by passing a vector of variable names to the group argument, and get back testing and training sets with argument bothSets = TRUE)]

```{r}
set.seed(1222)

# get how many rows we have in total to work out the percentage
n_data <- nrow(titanic_set)

# create a test sample index
test_index <- sample(1:n_data, size = n_data*0.2)

# create test set
titanic_set_test  <- slice(titanic_set, test_index)

# create training set
titanic_set_train <- slice(titanic_set, -test_index)
```

check the test and train datasets are ballanced: 

```{r}
titanic_set_test %>%
 janitor::tabyl(survived)
```

```{r}
titanic_set_train %>%
 janitor::tabyl(survived)
```

## 1.4 Question 4

Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
# build tree model based on training dataset
titanic_fit <- rpart(
  formula = survived ~ ., 
  data = titanic_set_train, 
  method = 'class'
)

# plot the tree model
rpart.plot(titanic_fit, 
           yesno = 2, 
           fallen.leaves = TRUE, 
           faclen = 6, 
           digits = 2)
```

## 1.5 Question 5

Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.

* There is 712 passengers entering our model.
* Looking at the variables that decision tree model picked up as important: sex, pclass, age_status, sib_sp, parch and embarked.
* The predicted result for a datapoint at the node (Survived or Not Survived in this example) is on the top line.
* The second line in a node contains probability of a *not survived* result expressed as a decimal. So eg. if a passenger was male, he had 0.21 chance of surviving. If a passenger was female, she had 0.75 chance to survive.
* If the passenger was male traveling in 2nd or 3rd class, he had 0.16 chance of surviving, while male travelling in 1st class has 0.41 chance of surviving. 
* Regarding to our model, 43% of the population in our model were male traveling in 2nd or 3rd class, older than 16 years

note, we can see the rules it has used to make the tree if we type the following:

```{r}
rpart.rules(titanic_fit, cover = TRUE)
```

## 1.6 Question 6

Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset.

```{r}
# use trained model to create predictions on test dataset
# add the predictions
titanic_test_pred <- titanic_set_test %>%
  add_predictions(titanic_fit, type = 'class')
```

```{r}
# look at the variables used in our decision tree
titanic_test_pred %>% 
  select("sex", "pclass", "age_status", "sib_sp", "embarked", "parch", "survived", "pred")
```

check model performance

```{r}
# confusion matrix
conf_mat <- titanic_test_pred %>% 
  tabyl(survived, pred)
conf_mat
```

I can also use confusionMatrix function from the caret package for the decision tree model performance summary:
### My three model has accuracy of 78.9%

```{r}
confusionMatrix(titanic_test_pred$survived, titanic_test_pred$pred)
```
### The decision tree model is performing well having accuracy of 78.9%. It predicted 85+36 TP and TN, whilst only 5+20 FP and FN.
### It has sensitivity (= true positive rate) of 0.7596 and specificity (= true negative rate) of 0.8684.